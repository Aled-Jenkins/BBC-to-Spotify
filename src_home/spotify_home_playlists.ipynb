{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spotipy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spotipy\n",
    "import hashlib\n",
    "from spotipy.oauth2 import SpotifyClientCredentials\n",
    "from spotipy.oauth2 import SpotifyOAuth\n",
    "from dotenv import load_dotenv\n",
    "import re\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "\n",
    "load_dotenv('../secrets/.env', override=True)\n",
    "\n",
    "scope = [\"playlist-modify-private\",\"playlist-read-private\",\"user-library-modify\",\"user-library-read\"]\n",
    "\n",
    "spotify = spotipy.Spotify(auth_manager=SpotifyOAuth(scope=scope))\n",
    "\n",
    "my_id = spotify.current_user()['id']\n",
    "\n",
    "%run ../src/useful_functions.ipynb\n",
    "%run ../src/spotify_scraping.ipynb\n",
    "%run ../src/spotify_scraping_playlists.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks = get_spotify_tracks()\n",
    "albums = get_spotify_albums()\n",
    "artists = get_spotify_artists()\n",
    "playlists = get_spotify_playlists()\n",
    "playlist_tracks = get_spotify_playlist_tracks()\n",
    "library = get_spotify_library()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Track ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3s9RxyseMXYLTOePGAADSb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1RGYjwj7R7CYwNePNZfkgW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4sys6H7gj0kgsa2bUx0IeW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2bbNjtgjr0ZOaPK7SOcVbV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>45WduJCqST7pBJPvxZ6ZgU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6oO10y1h2VyxJQfomG4CtH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>78rIJddV4X0HkNAInEcYde</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6Slaf2WBzQA86oS7MNMUNS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7cBhzkTWSpHBGAiCZzSika</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>72kdzT0WS77s10faqHsuTa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9268 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Track ID\n",
       "0   3s9RxyseMXYLTOePGAADSb\n",
       "0   1RGYjwj7R7CYwNePNZfkgW\n",
       "0   4sys6H7gj0kgsa2bUx0IeW\n",
       "0   2bbNjtgjr0ZOaPK7SOcVbV\n",
       "0   45WduJCqST7pBJPvxZ6ZgU\n",
       "..                     ...\n",
       "0   6oO10y1h2VyxJQfomG4CtH\n",
       "0   78rIJddV4X0HkNAInEcYde\n",
       "0   6Slaf2WBzQA86oS7MNMUNS\n",
       "0   7cBhzkTWSpHBGAiCZzSika\n",
       "0   72kdzT0WS77s10faqHsuTa\n",
       "\n",
       "[9268 rows x 1 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_library(max=10000, without_duplicates=False)\n",
    "#library = library.drop_duplicates(subset='Track ID', keep='last')\n",
    "#temp = library.groupby(['Track ID'])['Track ID'].count()\n",
    "#temp = pd.DataFrame(temp[temp > 1].index).merge(tracks, how = 'left', on = 'Track ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "offset = 0\n",
    "total = 1000\n",
    "temp = pd.DataFrame()\n",
    "\n",
    "while offset<total:\n",
    "    temp_playlists = spotify.current_user_playlists(limit=50, offset=offset)\n",
    "    temp = pd.concat([temp,pd.DataFrame.from_dict({'Playlist ID': [x['id'] for x in temp_playlists['items']],\n",
    "                                                   'Playlist Name': [x['name'] for x in temp_playlists['items']],\n",
    "                                                   'Playlist Description': [x['description'] for x in temp_playlists['items']]})])\n",
    "    if offset == 0:\n",
    "        total = temp_playlists['total']\n",
    "    offset += 50\n",
    "\n",
    "del(offset, total, temp_playlists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38/38 [01:37<00:00,  2.56s/it]\n",
      "100%|██████████| 10/10 [01:27<00:00,  8.76s/it]\n"
     ]
    }
   ],
   "source": [
    "playlists_to_run = list(temp[[((x == '**') or (x[0:3] == '** ')) for x in temp['Playlist Description']]]['Playlist ID']) \n",
    "for playlist_id in tqdm(playlists_to_run):\n",
    "    get_playlist(playlist_id, with_tracks = True)\n",
    "    \n",
    "playlists_to_run = list(temp[[((x == '*****') or (x[0:6] == '***** ')) for x in temp['Playlist Description']]]['Playlist ID']) \n",
    "for playlist_id in tqdm(playlists_to_run):\n",
    "    get_playlist(playlist_id, with_tracks = True)\n",
    "\n",
    "del(temp, playlists_to_run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping_df = tracks.merge(library, on='Track ID', how='left',indicator = True)\n",
    "mapping_df = mapping_df[mapping_df['Is Track Local'] == False]\n",
    "mapping_df = mapping_df.merge(mapping_df[(mapping_df['_merge'] == 'both')][[\"Track External ID's\",\"Track ID\"]], on = [\"Track External ID's\"], how='left', suffixes=[\"\",\" Mapped\"])\n",
    "mapping_df = (\n",
    "    mapping_df.merge(mapping_df[pd.isna(mapping_df['Track ID Mapped'])]\n",
    "                     .groupby([\"Track External ID's\",])[[\"Track External ID's\",'Track ID','Track Popularity']]\n",
    "                     .apply(lambda x: x.sort_values(by = ['Track Popularity'], ascending=False).head(1))\n",
    "                     .reset_index(drop = True)[[\"Track External ID's\", \"Track ID\"]], on = [\"Track External ID's\"], how='left', suffixes=[\"\",\" Mapped New\"])\n",
    ")\n",
    "mapping_df['Track ID Mapped'] = mapping_df.apply(lambda x: x['Track ID Mapped'] if not pd.isna(x['Track ID Mapped']) else x['Track ID Mapped New'], axis=1)\n",
    "#mapping_df['Track ID Mapped'] = mapping_df.apply(lambda x: x['Track ID'] if pd.isna(x['Track ID Mapped']) else x['Track ID Mapped'], axis=1)\n",
    "test_df = mapping_df.groupby(['Track ID', \"Track External ID's\"]).agg('count')\n",
    "test_df = test_df[test_df['Track ID Mapped'] > 1].sort_values(by=['Track Name']).reset_index()\n",
    "mapping_df = mapping_df[['Track ID', 'Track ID Mapped']]\n",
    "\n",
    "if test_df.size == 0:\n",
    "    del(test_df)\n",
    "else:\n",
    "    print('Number of Errors: ',test_df.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted = playlist_tracks.merge(playlists, how = 'left', left_on = 'Playlist ID', right_on = 'id')\n",
    "sorted = (\n",
    "    sorted[((sorted['description'] == \"**\") | (sorted['description'].apply(lambda x: x[0:3] == \"** \")))]\n",
    "    .merge(library, how = 'outer', on = 'Track ID', indicator = True)\n",
    "    .merge(mapping_df, how = 'left', on = 'Track ID')\n",
    "    .merge(tracks, how = 'left', on = 'Track ID')\n",
    "    .merge(albums, how = 'left', on = 'Album ID')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [02:17<00:00, 15.26s/it]\n"
     ]
    }
   ],
   "source": [
    "temp = playlist_tracks.merge(playlists, how = 'left', left_on = 'Playlist ID', right_on = 'id')\n",
    "temp = (\n",
    "    temp[((temp['description'] == \"*****\") | (temp['description'].apply(lambda x: x[0:6] == \"***** \")))]\n",
    "    .merge(library, how = 'left', on = 'Track ID', indicator = True)\n",
    "    .merge(mapping_df, how = 'left', on = 'Track ID')\n",
    "    .merge(tracks, how = 'left', on = 'Track ID')\n",
    ")\n",
    "temp = temp[temp['name'] != 'Albums to Listen To']\n",
    "temp = temp.groupby('Track ID Mapped').head(1)[['Track ID', 'Track ID Mapped', 'Playlist ID', 'Position Number', 'name', 'Track Name', '_merge']]\n",
    "temp = temp.merge(temp[['Track ID', '_merge']].rename(columns = {'Track ID': 'Track ID Mapped', '_merge': '_merge Mapped'}), how = 'left', on = 'Track ID Mapped')\n",
    "\n",
    "for playlist_id in tqdm(list(temp['Playlist ID'].drop_duplicates())):\n",
    "    \n",
    "    df = temp[temp['Playlist ID'] == playlist_id]\n",
    "    if playlist_id in [#'65jX0kBNpAEO7TcDQrkDai', \n",
    "                       '0UL0ZXu3J2ivcyYJEXCl5a', \n",
    "                       '0bIch9WkT5N5pIWnscc0Zx', \n",
    "                       '35FowWuDxV2wsuuw2goxIJ', \n",
    "                       '4iPj2uCtn4PSleqBk0IXbo', \n",
    "                       '5Tf5DugxlW3BbNoK76h7db',\n",
    "                       '0SmY9kTeNMWRwUJyNWvaFA']:\n",
    "        df = df[((df['_merge'] != 'both') & (df['_merge Mapped'] != 'both'))]\n",
    "    new_tracks = list(df['Track ID Mapped'])\n",
    "    edit_playlist_tracks(playlist_id, new_tracks, order=False)\n",
    "    \n",
    "del(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make_playlist(title, description)\n",
    "#edit_playlist_tracks(playlists[playlists['name'] == title]['id'][0], new_tracks)\n",
    "\n",
    "#edit_playlist_details(user=my_id, playlist_id = playlist_id, name = name', description = 'description')\n",
    "#get_playlist(playlist_id, with_tracks = False)\n",
    "#get_playlist(playlist_id = playlist_id)\n",
    "#delete_playlist(playlist_id = playlist_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "playlist_tracks.to_pickle('../data/spotify_playlist_tracks.pkl')\n",
    "playlists.to_pickle('../data/spotify_playlists.pkl')\n",
    "tracks.to_pickle('../data/spotify_tracks.pkl')\n",
    "albums.to_pickle('../data/spotify_albums.pkl')\n",
    "artists.to_pickle('../data/spotify_artists.pkl')\n",
    "library.to_pickle('../data/spotify_library.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
